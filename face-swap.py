import argparse
import cv2
import numpy as np
from insightface.app import FaceAnalysis
from gfpgan import GFPGANer
from numpy.linalg import norm
import torch

# ----------------------------
# åˆå§‹åŒ– InsightFace
# ----------------------------
print("Loading InsightFace...")
app = FaceAnalysis(providers=['CPUExecutionProvider'])
app.prepare(ctx_id=-1, det_size=(640, 640))
print("InsightFace loaded.")

# ----------------------------
# Argparse
# ----------------------------
def parse_args():
    parser = argparse.ArgumentParser(description="Face Swap using InsightFace + GFPGAN + Reference Face")
    parser.add_argument('--source', type=str, required=True, help='C:/Users/tony0/Downloads/Homework1/Ma.bmp"')
    parser.add_argument('--input', type=str, required=True, help='C:/Users/tony0/Downloads/Homework1/AI-muscle.mp4')
    parser.add_argument('--output', type=str, required=True, help='C:/Users/tony0/Downloads/Homework1/output.mp4')
    parser.add_argument('--reference', type=str, required=True, help='C:/Users/tony0/Downloads/Homework1/è¢å¹•æ“·å–ç•«é¢ 2025-10-22 094048.png')
    parser.add_argument('--gfpgan', action='store_true', help='Use GFPGAN enhancement')
    parser.add_argument('--threshold', type=float, default=0.3, help='Cosine similarity threshold')
    return parser.parse_args()

# ----------------------------
# è¼‰å…¥å½±åƒ
# ----------------------------
def load_image(path):
    img = cv2.imread(path)
    if img is None:
        raise ValueError(f"Cannot load image from {path}")
    return img

# ----------------------------
# è¨ˆç®— cosine similarity
# ----------------------------
def cosine_similarity(v1, v2):
    return np.dot(v1, v2) / (norm(v1) * norm(v2))

# ----------------------------
# åˆå§‹åŒ– GFPGAN
# ----------------------------
def init_gfpgan():
    use_cuda = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 7
    device = "cuda" if use_cuda else "cpu"
    print(f"Initializing GFPGAN on {device}...")

    try:
        gfpgan_model = GFPGANer(
            model_path='experiments/pretrained_models/GFPGANv1.3.pth',
            upscale=1,
            arch='clean',
            device=device
        )
        print(f"GFPGAN loaded on {device}.")
        return gfpgan_model
    except Exception as e:
        print(f"GFPGAN initialization failed: {e}")
        return None


def warp_triangle(img1, img2, t1, t2):
    r1 = cv2.boundingRect(np.float32([t1]))
    r2 = cv2.boundingRect(np.float32([t2]))

    t1_rect = []
    t2_rect = []
    for i in range(3):
        t1_rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))
        t2_rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))

    mask = np.zeros((r2[3], r2[2], 3), dtype=np.float32)
    cv2.fillConvexPoly(mask, np.int32(t2_rect), (1.0, 1.0, 1.0), 16, 0)

    M = cv2.getAffineTransform(np.float32(t1_rect), np.float32(t2_rect))
    warped = cv2.warpAffine(
        img1[r1[1]:r1[1]+r1[3], r1[0]:r1[0]+r1[2]],
        M,
        (r2[2], r2[3]),
        None,
        flags=cv2.INTER_LINEAR,
        borderMode=cv2.BORDER_REFLECT_101
    )
    img2_rect = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]]
    img2_rect = img2_rect * (1 - mask) + warped * mask
    img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2_rect

# ----------------------------
# æ›è‡‰å‡½æ•¸
# ----------------------------
def swap_faces(source_img, target_img, ref_embedding, gfpgan=None, alpha=0.65, threshold=0.3):

    source_faces = app.get(source_img)
    target_faces = app.get(target_img)
    if len(source_faces) == 0 or len(target_faces) == 0:
        return target_img

    source_face = source_faces[0]
    source_landmarks = source_face.landmark_2d_106

    output_img = target_img.copy()

    for t_face in target_faces:
        target_embedding = t_face.embedding
        sim = cosine_similarity(ref_embedding, target_embedding)
        if sim < threshold:
            continue

        target_landmarks = t_face.landmark_2d_106.astype(np.float32)

        top_y = np.min(target_landmarks[:, 1])
        top_x = np.mean(target_landmarks[:, 0])
        h = np.max(target_landmarks[:, 1]) - np.min(target_landmarks[:, 1])
        w = np.max(target_landmarks[:, 0]) - np.min(target_landmarks[:, 0])

        # =====================================================
        #  A) 25 é»é¡é ­ç¶²æ ¼ï¼šä¸Š/ä¸­/ä¸‹ ä¸‰å±¤ï¼ˆ7 + 9 + 9 = 25ï¼‰
        #     æ©«å‘è¦†è“‹é¡é ­èˆ‡é«®éš›ä¸‹ç·£ï¼Œç­‰è·åˆ†ä½ˆä»¥ç©©å®š Delaunayã€‚
        # =====================================================
        layers = [
            (-0.12 * h, 7),   # æ¥è¿‘çœ‰ä¸Šç·£
            (-0.20 * h, 9),   # é¡é ­ä¸­å±¤
            (-0.27 * h, 9),   # æ¥è¿‘é«®éš›ä¸‹ç·£
        ]
        extra_points_list = []
        for y_off, n_pts in layers:
            x_start = top_x - 0.35 * w
            x_end   = top_x + 0.35 * w
            xs = np.linspace(x_start, x_end, int(n_pts))
            ys = np.full_like(xs, top_y + y_off, dtype=np.float32)
            extra_points_list.append(np.stack([xs.astype(np.float32), ys], axis=1))
        extra_points = np.concatenate(extra_points_list, axis=0).astype(np.float32)  # shape: (25,2)

        all_target = np.vstack([target_landmarks, extra_points])  # (N+3,2)

        all_landmarks = all_target

        # ========= [é€™è£¡é–‹å§‹æ˜¯ä½ è¦æ’å…¥çš„ä»¿å°„ä¼°è¨ˆå€å¡Š] =========
        # ï¼ˆé¸ï¼‰åªç”¨ã€Œä¸ŠåŠè‡‰ã€ä¾†ä¼°ä»¿å°„ï¼Œå°è¡¨æƒ…æ›´ç©©
        tl = target_landmarks.astype(np.float32)
        sl = source_landmarks.astype(np.float32)
        y_med = np.median(tl[:, 1])
        upper_mask = tl[:, 1] < y_med  # ä¸ŠåŠè‡‰ï¼šçœ‰/çœ¼/é¼»æ¨‘é™„è¿‘

        tl_fit = tl[upper_mask] if np.sum(upper_mask) >= 10 else tl
        sl_fit = sl[upper_mask] if np.sum(upper_mask) >= 10 else sl

        # ä¼° targetâ†’source çš„ç›¸ä¼¼/ä»¿å°„ï¼ˆæ—‹è½‰+ç¸®æ”¾+å¹³ç§»ï¼‰
        M, _ = cv2.estimateAffinePartial2D(
            tl_fit, sl_fit,
            method=cv2.RANSAC,
            ransacReprojThreshold=3.0,
            maxIters=2000, confidence=0.99
        )

        def apply_affine(pts, M):
            pts_h = np.hstack([pts, np.ones((pts.shape[0], 1), dtype=np.float32)])  # (N,3)
            out = pts_h @ M.T  # (N,2)
            return out.astype(np.float32)

        if M is not None:
            extra_src = apply_affine(extra_points, M)  # æŠŠé¡å¤–é»å¸¶åˆ°ä¾†æºè‡‰åº§æ¨™
        else:
            # ä¼°ä¸åˆ°å°±é€€å›ä½ åŸæœ¬çš„ä¸­å¿ƒå¹³ç§»æ³•
            src_center = np.mean(source_landmarks, axis=0)
            tgt_center = np.mean(target_landmarks, axis=0)
            extra_src = src_center + (extra_points - tgt_center)

        # ä¾†æºæ‰€æœ‰é»ï¼ˆ106 + é¡å¤–å°æ‡‰é»ï¼‰
        all_source = np.vstack([source_landmarks.astype(np.float32), extra_src])
        # ========= [ä»¿å°„ä¼°è¨ˆå€å¡Šåˆ°æ­¤çµæŸ] =========


        # ---------- B) é€ä¸‰è§’å½¢ä»¿å°„ï¼šç”¨ all_target å»º Delaunay ----------
        # ç”¨ cv2.Subdiv2Dï¼Œä½†è¦æŠŠä¸‰è§’å½¢é ‚é»ã€Œå°å›ã€æˆ‘å€‘çš„é»ç´¢å¼•
        rect = cv2.boundingRect(all_target.astype(np.float32))
        subdiv = cv2.Subdiv2D(rect)
        for p in all_target:
            subdiv.insert((float(p[0]), float(p[1])))

        triangles = subdiv.getTriangleList().reshape(-1, 6)  # [x1,y1,x2,y2,x3,y3]

        # ç‚ºäº†æŠŠ getTriangleList() çš„æµ®é»åº§æ¨™å°å› our pointsï¼Œ
        # å»ºç«‹ä¸€å€‹ KD æŸ¥è¡¨ï¼ˆæˆ–ç°¡å–®æœ€è¿‘é„°ï¼‰ï¼šé€™æ¬¡ä¸€å®šç”¨ all_targetï¼Œä¸æ˜¯ target_landmarksï¼
        # ï¼ˆè‹¥æ“”å¿ƒèª¤é…ï¼Œå¯å…ˆå››æ¨äº”å…¥å¾Œ dict æ˜ å°„ï¼‰
        # é€™è£¡ç”¨æœ€è¿‘é„°ï¼Œä¸¦åšå”¯ä¸€æ€§æª¢æŸ¥é¿å…é€€åŒ–ä¸‰è§’å½¢ã€‚
        warped_source = np.zeros_like(target_img)

        for tri in triangles:
            p1 = np.array([tri[0], tri[1]], dtype=np.float32)
            p2 = np.array([tri[2], tri[3]], dtype=np.float32)
            p3 = np.array([tri[4], tri[5]], dtype=np.float32)

            # æ‰¾åˆ°å„é ‚é»åœ¨ all_target ä¸­çš„ç´¢å¼•
            idx1 = np.argmin(np.linalg.norm(all_target - p1, axis=1))
            idx2 = np.argmin(np.linalg.norm(all_target - p2, axis=1))
            idx3 = np.argmin(np.linalg.norm(all_target - p3, axis=1))

            # è·³éé€€åŒ–æˆ–é‡è¤‡ç´¢å¼•çš„ä¸‰è§’å½¢
            if len({idx1, idx2, idx3}) < 3:
                continue

            pts_tgt = np.float32([all_target[idx1], all_target[idx2], all_target[idx3]])
            pts_src = np.float32([all_source[idx1], all_source[idx2], all_source[idx3]])

            warp_triangle(source_img, warped_source, pts_src, pts_tgt)

        # ğŸŸ¢ 2ï¸âƒ£ æ”¾å¤§æ•´é«”é®ç½©ç¯„åœ
        center = np.mean(all_landmarks, axis=0)
        scale_x = 1.10
        scale_y = 1.25
        expanded_landmarks = (all_landmarks - center) * [scale_x, scale_y] + center

        # ğŸŸ£ 3ï¸âƒ£ å»ºç«‹æœ€çµ‚é®ç½©
        mask = np.zeros(target_img.shape[:2], dtype=np.uint8)
        cv2.fillConvexPoly(mask,
                        cv2.convexHull(expanded_landmarks.astype(np.int32)),
                        255)


        # é‚Šç·£å¹³æ»‘ï¼ˆæ³¨æ„ kernel è¦å¥‡æ•¸ï¼‰
        # å…ˆé«˜æ–¯å†å½¢æ…‹è†¨è„¹ï¼Œè®“å…©å´æ›´ã€Œæœ‰æ–™ã€
        mask = cv2.GaussianBlur(mask, (13, 13), 0)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))
        mask = cv2.dilate(mask, kernel, iterations=1)

        # èˆ‡ warped_source çš„æœ‰æ•ˆå€åŸŸå–äº¤é›†ï¼ˆé¿å…é¡é ­é»‘ï¼‰
        valid = (warped_source.sum(axis=2) > 0).astype(np.uint8) * 255
        mask = cv2.bitwise_and(mask, valid)

        # --------- C. èåˆï¼ˆç–Šåˆ° output_imgï¼Œé target_imgï¼‰---------
        mask_f = (mask.astype(np.float32) / 255.0)[..., None] * float(alpha)
        swapped = (warped_source.astype(np.float32) * mask_f
                   + output_img.astype(np.float32) * (1.0 - mask_f)).astype(np.uint8)


     # ---- ä½¿ç”¨æ–°ç‰ˆ GFPGAN API ----
        if gfpgan is not None:
            try:
                # é€™è£¡ç”¨ warped_source é€²ä¿®å¾©ï¼Œå†é‡åšèåˆæœƒæ›´è‡ªç„¶
                restored_faces, restored_img, _ = gfpgan.enhance(
                    warped_source, has_aligned=False, only_center_face=False, paste_back=True
                )
                if isinstance(restored_img, np.ndarray) and restored_img.size > 0:
                    warped_source = restored_img
                    # é‡æ–°è¨ˆç®— valid & èåˆï¼ˆé¿å…ç”¨èˆŠçš„ swappedï¼‰
                    valid = (warped_source.sum(axis=2) > 0).astype(np.uint8) * 255
                    mask = cv2.bitwise_and(mask, valid)
                    mask_f = (mask.astype(np.float32) / 255.0)[..., None] * float(alpha)
                    swapped = (warped_source.astype(np.float32) * mask_f
                               + output_img.astype(np.float32) * (1.0 - mask_f)).astype(np.uint8)
            except Exception as e:
                print(f"GFPGAN enhance failed, fallback to original warp: {e}")
                # å¤±æ•—å°±ä½¿ç”¨åŸæœ¬ warpï¼Œä¸è¿”å› None
                pass

        output_img = swapped

    return output_img


# ----------------------------
# å½±ç‰‡è™•ç†
# ----------------------------
def process_video(source_img, input_path, output_path, ref_embedding, gfpgan=None, threshold=0.3):
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        raise ValueError(f"Cannot open video {input_path}")

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        swapped = swap_faces(source_img, frame, ref_embedding, gfpgan=gfpgan, threshold=threshold)
        if swapped is None:
            cap.release()
            out.release()
            print("\nGFPGAN failed during video processing. Re-running without GFPGAN...")
            return False

        out.write(swapped)
        frame_idx += 1

        # é¡¯ç¤ºç™¾åˆ†æ¯”é€²åº¦æ¢
        progress = (frame_idx / total_frames) * 100
        bar_length = 30  # é€²åº¦æ¢é•·åº¦
        filled_length = int(bar_length * frame_idx // total_frames)
        bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
        print(f"\rProgress: |{bar}| {progress:6.2f}% ({frame_idx}/{total_frames})", end='')

    cap.release()
    out.release()
    print("\nVideo processing finished.")
    return True

# ----------------------------
# ä¸‰è§’å½¢åˆ‡å‰²
# ----------------------------




# ----------------------------
# ä¸»ç¨‹å¼
# ----------------------------
def main():
    args = parse_args()
    source_img = load_image(args.source)
    reference_img = load_image(args.reference)

    ref_faces = app.get(reference_img)
    if len(ref_faces) == 0:
        raise ValueError("Reference face not detected!")
    ref_embedding = ref_faces[0].embedding

    gfpgan_model = None
    if args.gfpgan:
        gfpgan_model = init_gfpgan()

    success = process_video(source_img, args.input, args.output, ref_embedding, gfpgan=gfpgan_model, threshold=args.threshold)

    # å¦‚æœ GFPGAN æ•´æ®µå½±ç‰‡å¤±æ•—ï¼Œé‡æ–°è·‘ä¸€æ¬¡ CPU-only
    if not success:
        print("Re-running video without GFPGAN...")
        process_video(source_img, args.input, args.output, ref_embedding, gfpgan=None, threshold=args.threshold)

if __name__ == "__main__":
    main()